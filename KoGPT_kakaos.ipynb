{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKB98N9Uw2YA4VB0kT7Dsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/absolutelydawn/TestNeoX/blob/main/KoGPT_kakaos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch # Pytorch 기반의\n",
        "!pip install transformers # transformers 에 속해있는 KoGPT모델\n",
        "!pip install pandas # pandas로 데이터 처리\n",
        "!pip install nltk # BLEU 점수를 계산하기 위해 Natural Language Toolkit (NLTK)를 사용\n",
        "!pip install accelerate # transformers와 같이 허깅페이스에서 제공하는 속도 최적화등 계산 라이브러리\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xyKGOGQragG",
        "outputId": "bc3f787b-5ded-48ba-ec5d-ae53e99bf82a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "nJOYdhXp0tAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 만료로 실행 안됨.. 로컬 환경(Pycharm)에서 실행되는 코드로 변경 후 실행해볼것\n",
        "# finetunning KoGPT(카카오브레인)\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import urllib.request\n",
        "\n",
        "# 데이터 파일 다운로드\n",
        "data_url = 'https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv'\n",
        "file_name = 'Chatbot_data.csv'\n",
        "urllib.request.urlretrieve(data_url, file_name)\n",
        "\n",
        "# 데이터를 불러와서 DataFrame으로 읽기\n",
        "df_train = pd.read_csv(file_name)\n",
        "\n",
        "# 데이터 확인\n",
        "print(df_train.head())\n",
        "\n",
        "# 데이터 로딩 (훈련 데이터와 별도의 테스트 데이터 사용)\n",
        "df_test = pd.read_csv('Chatbot_data.csv')  # 테스트 데이터 파일 사용 : Chatbot_test_data.csv > Chatbot_data.csv로 파일명 변경\n",
        "\n",
        "text_data_train = df_train['Q']\n",
        "labels_train = df_train['A']\n",
        "\n",
        "text_data_test = df_test['Q']\n",
        "labels_test = df_test['A']\n",
        "\n",
        "# 모델 및 토크나이저 로딩\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',\n",
        "    bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    torch_dtype='auto', low_cpu_mem_usage=True\n",
        ").to(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "_ = model.eval()\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 4\n",
        "learning_rate = 0.0001\n",
        "epochs = 5\n",
        "\n",
        "# 데이터로더 설정 (테스트 데이터로더 추가)\n",
        "train_dataset = ChatbotDataset(text_data_train, tokenizer)\n",
        "test_dataset = ChatbotDataset(text_data_test, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 옵티마이저와 손실 함수 설정\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs = batch.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "        outputs = model(inputs, labels=inputs)\n",
        "        loss = loss_fn(outputs.logits.view(-1, outputs.logits.size(-1)), inputs.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}] - Loss: {average_loss:.4f}')\n",
        "\n",
        "# 모델 성능 평가\n",
        "model.eval()\n",
        "references = []  # 정답 문장 리스트\n",
        "hypotheses = []  # 생성된 문장 리스트\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    inputs = batch.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "    generated_ids = model.generate(inputs, max_length=50, num_return_sequences=1)\n",
        "\n",
        "    for gen_id in generated_ids:\n",
        "        gen_text = tokenizer.decode(gen_id, skip_special_tokens=True)\n",
        "        hypotheses.append(gen_text)\n",
        "\n",
        "    for label in batch.tolist():\n",
        "        ref_text = tokenizer.decode(label, skip_special_tokens=True)\n",
        "        references.append([ref_text])\n",
        "\n",
        "# 모델 저장\n",
        "model_save_path = \"chatbot_model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "# BLEU 점수 계산 : 높을 수록 좋은 점수\n",
        "bleu_score = corpus_bleu(references, hypotheses)\n",
        "print(f'BLEU Score: {bleu_score:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqFPxV7VzEyE",
        "outputId": "e451ad66-f5c8-477f-a92f-22b454b30489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Q            A  label\n",
            "0           12시 땡!   하루가 또 가네요.      0\n",
            "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
            "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
            "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
            "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 확인(간단하게)\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import sys\n",
        "\n",
        "# 모델 및 토크나이저 로딩\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',\n",
        "    bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    torch_dtype='auto', low_cpu_mem_usage=True\n",
        ").to(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "_ = model.eval()\n",
        "\n",
        "# 저장된 모델 로드\n",
        "model_save_path = \"chatbot_model.pth\"\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "\n",
        "# 사용자 입력 받기 및 대답 생성\n",
        "while True:\n",
        "    user_input = input(\"사용자: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # 사용자 입력을 토큰화하여 모델 입력으로 변환\n",
        "    input_ids = tokenizer.encode(user_input, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # 모델을 사용하여 답변 생성\n",
        "    generated_ids = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
        "\n",
        "    # 생성된 답변 출력\n",
        "    chatbot_response = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    print(\"Chatbot:\", chatbot_response)\n"
      ],
      "metadata": {
        "id": "4O41pPwT3ofZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}